library(MASS)
library(ggplot2)

medias <- c(10, 15, 12)
varianzas_covarianzas <- matrix(c(10, 8, 7,
                                  8, 11, 9,
                                  7, 9, 13), byrow = TRUE, ncol = 3)
n <- 100
datos_simulados1 <- mvrnorm(n, medias, varianzas_covarianzas) %>% data.frame()
apply(datos_simulados1, 2, mean)
cor(datos_simulados1)


medias_2 <- c(2, 5, 1.2)
varianzas_covarianzas_2 <- matrix(c(1.5, -1.5, 0.7,
                                    -1.5, 3.1, 0.2,
                                    0.7, 0.2, 1.3), byrow = TRUE, ncol = 3)

n <- 100
datos_simulados_2 <- mvrnorm(n, medias_2, varianzas_covarianzas_2) %>% data.frame()
apply(datos_simulados_2, 2, mean)
cor(datos_simulados_2)

datos_simulados1[, 'grupo'] <- 'G1'
datos_simulados_2[, 'grupo'] <- 'G2'

datos_kmeans <- bind_rows(datos_simulados1, datos_simulados_2)

datos_kmeans

# Gráfico grupos

datos_kmeans %>%  ggplot(aes(X1,X2,  color = grupo)) +
  geom_point()

# kmeans
agrupacion <- kmeans(datos_kmeans[, -4], 2) #parametros(datos, # de grupos), quitamos la columna 4 pq kmeans solo toma datos numericos

grupos_predichos <- factor(agrupacion$cluster)
levels(grupos_predichos) <- c('G1', 'G2')
(datos_kmeans$grupo == grupos_predichos) %>% mean()

# Punto del parcial:
# [Parte 1]
#   1. Generar 2 grupos aleatorios de una normal, como lo generado en clase, con tres variables
#   2. Hacer el algoritmo de k-means para agrupar esos datos
#   3. Calcular cuántos de los puntos fueron mal clasificados y calcular el accuracy
# [Parte 2]
#   1. Repetir el experimento de la parte 1 500 veces y hacer un montecarlo para el accurary
#   2. Hacer variaciones de los centroides para que cada vez estén mas cerca y almacenar el accuracy promedio para cada caso
#   3. Hacer un gráfico de accuracy vs distancia ecuclideana entre centroides
#         ej: **accuracy <- mean(predicted == test$Species)**

distancias <- dist(datos_kmeans[, -4])
arbol <- hclust(distancias)
arbol_corte <- cutree(arbol, 4)

rect.hclust(arbol, 2)
plot(arbol)

# # Punto 3
# 
# 3.Considera el algoritmo KNN para la clasificación de N muestras en k clases y el ajuste del valor de k a través de remuestreo con reemplazo. Sea pi
# La probabilidad de que una muestra pertenezca a la categoría i-ésima.
# 
#   1. ¿Cuál es el estimador de pi?
#   2. ¿Dicho estimador es insesgado?
#   3. ¿Cómo se selecciona el valor óptimo de k?
#     
# 5. ¿Cuál es la diferencia entre los algoritmos de clasificación y de agrupamiento?
# 6. Explicar la interpretación de los odds ratio en la regresión logística